{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to database with uri: mongodb://admin:password@localhost:27017 successful\n"
     ]
    }
   ],
   "source": [
    "from rag_tests.db.mongo import connection\n",
    "from rag_tests.core import get_logger\n",
    "logger = get_logger(__name__)\n",
    "mongo_db_connector = connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_posts_from_mongo_by_author_firstname(firstname:str):\n",
    "    _database = mongo_db_connector.get_database(\"scrabble\")\n",
    "    collection = _database[\"posts\"]\n",
    "    return collection.find({\"author_id\": {\"$regex\": firstname, \"$options\": \"i\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_tests.models.base import BaseModel\n",
    "from rag_tests.models import PostsRawModel, PostChunkModel, PostCleanedModel, PostEmbeddedChunkModel\n",
    "from qdrant_client.models import Batch\n",
    "from rag_tests.models.clean import PostCleanedModel\n",
    "from rag_tests.data_logic.cleaning_data_handlers import PostCleaningHandler\n",
    "from rag_tests.data_logic.chunking_data_handlers import PostChunkingHandler\n",
    "from rag_tests.data_logic.embedding_data_handlers import PostEmbeddingDataHandler\n",
    "from rag_tests.qdrant_db import QdrantDatabaseConnector\n",
    "from rag_tests.config import settings\n",
    "collection_name = f\"TEST_VARUN_{settings.EMBEDDING_MODEL_ID.replace('/','_')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_posts_from_warehouse_by_linkedin_id(linkedin_id:str):\n",
    "#     _data_warehouse= mongo_db_connector.get_database(\"srabble_raw\")\n",
    "#     collection = _data_warehouse[\"linkedin_users_all_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'platform', 'content', 'author_id'])\n"
     ]
    }
   ],
   "source": [
    "cursor = fetch_posts_from_mongo_by_author_firstname(\"varun\")\n",
    "raw_posts = []\n",
    "seen_posts = set()\n",
    "flag =True\n",
    "for post in cursor:\n",
    "    if flag : \n",
    "        print(post.keys())\n",
    "        flag = False\n",
    "    entry_id = post[\"_id\"]\n",
    "    if entry_id not in seen_posts:\n",
    "        seen_posts.add(entry_id)\n",
    "        # remove _id from post\n",
    "        post.pop(\"_id\")\n",
    "\n",
    "        raw_posts.append(PostsRawModel(entry_id=entry_id, **post))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_posts= raw_posts[:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cleaned posts: 110\n"
     ]
    }
   ],
   "source": [
    "cleaning_handler  = PostCleaningHandler()\n",
    "cleaned_posts = []\n",
    "for raw_post in raw_posts:\n",
    "    cleaned_obj = cleaning_handler.clean(raw_post)\n",
    "    cleaned_posts.append(cleaned_obj)\n",
    "\n",
    "print(f\"Number of cleaned posts: {len(cleaned_posts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunking_handler = PostChunkingHandler()\n",
    "chunked_posts = []\n",
    "for cleaned_post in cleaned_posts:\n",
    "    chunked_obj = chunking_handler.chunk(cleaned_post)\n",
    "    chunked_posts.append(chunked_obj)\n",
    "\n",
    "print(f\"Number of chunked posts: {len(chunked_posts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_handler = PostEmbeddingDataHandler()\n",
    "embedded_posts:list[PostEmbeddedChunkModel] = []\n",
    "for chunked_post in chunked_posts:\n",
    "    embedded_obj = embedding_handler.embedd(chunked_post[0])\n",
    "    embedded_posts.append(embedded_obj)\n",
    "\n",
    "print(f\"Number of embedded posts: {len(embedded_posts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qdrant_db = QdrantDatabaseConnector()\n",
    "payloads = [\n",
    "    post.to_payload() for post in embedded_posts\n",
    "]\n",
    "ids, vectors, metadatas = zip(*payloads)\n",
    "\n",
    "collection_name = f\"TEST_VARUN_{settings.EMBEDDING_MODEL_ID.replace('/','_')}\"\n",
    "qdrant_db.create_vector_collection(collection_name)\n",
    "qdrant_db.write_data(collection_name, points=Batch(ids=ids, vectors=vectors, payloads=metadatas))\n",
    "print(f\"Chala bhai daaldi {len(embedded_posts)} posts qdrant mei\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from rag_tests.llm.chain import GeneralQueryChain\n",
    "from rag_tests.rag.retreiver import VectorRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "from rag_tests.config import settings\n",
    "from rag_tests.llm.prompt_templates import GetToneUnderstandingPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "print(\"Starting the process\")\n",
    "\n",
    "author_id = \"https://www.linkedin.com/in/varunaggarwal2\"\n",
    "query = \"\"\"\n",
    "    My author_id is https://www.linkedin.com/in/varunaggarwal2\n",
    "    i want to draft a LinkedIn post discussing how to build startups?.\n",
    "    \"\"\"\n",
    "retriever = VectorRetriever(query=query)\n",
    "print(collection_name)\n",
    "hits = retriever.retrieve_top_k(k=6, to_expand_to_n_queries=5, collection_name=collection_name)\n",
    "\n",
    "reranked_hits = retriever.rerank(hits=hits, keep_top_k=5)\n",
    "for rank, hit in enumerate(reranked_hits):\n",
    "    print(f\"{rank}: {hit}\")\n",
    "# reranked_hits = [\"himanshu aggarwal < newline / > and i will talk through the aspiring minds story today at 530pm! < newline / > we will bring you insights using change engine ' s ace framework of building successful startups. < newline / > a. identifying the problem to solve < newline / > b. finding the right business model / markets < newline / > c. developing escape velocity < newline / > do not miss, register here : < newline / > [ url ] out ace here : < newline / > [ url ]\", \"join < newline / > manish gupta < newline / > and me today evening for an insightful conversation on ' building an ai startup in times of llm '. whether you are a seasoned entrepreneur or just starting your journey, this session is designed to be valuable for both sets of individuals. do not miss.....\", 'at change engine, we talk to several ai startups. < doublelinebreak / > what do i look for in startups when making an investing decision? < doublelinebreak / > 1. problem understanding : do the founders truly understand the problem? have they done value chain mapping to know how the process works today, where the inefficiencies are, and why they exist? < doublelinebreak / > 2. product demo : the demo is crucial. is the ui / ux seamless? how well does the ai solve the problem? is it a painkiller or just a', 'the fight for the ace fellowship is heating up. we have 200 + applications from aspiring entrepreneurs who wants to participate in our 6 month program to build a < newline / > hashtag < newline / > # < newline / > jobtech < newline / > startup. < newline / > in parallel, we have started nurturing these entrepreneurs to fine tune their ideas to build scalable and impactful startups. < newline / > mukul singhal < newline / > from < newline / > pravega ventures < newline / > and i will discuss this thursday, \" what business models attract', 'congratulations to the inaugural ace startup cohort 2023! < newline / > we are thrilled to announce that we found these kickass entrepreneurs and will be joining their exciting journey to success. with our passion for innovation and years of entrepreneurial experience, we will nurture their thoughts and collectively brew some groundbreaking ideas that can become thriving organizations over the next 6 months. < newline / > watch this space. we will keep you updated as these new founders make progress.']\n",
    "model = ChatOpenAI(model=settings.OPENAI_MODEL_ID, temperature=0)   \n",
    "get_tone_understanding_prompt_template = GetToneUnderstandingPromptTemplate()\n",
    "prompt_template = get_tone_understanding_prompt_template.create_template()\n",
    "chain = GeneralQueryChain().get_chain(\n",
    "    llm=model, output_key=\"tone_understanding\", template=prompt_template\n",
    ")\n",
    "response = chain.invoke({\"author_id\":\"https://www.linkedin.com/in/varunaggarwal2\", \"posts\":reranked_hits})\n",
    "logger.info(f\"Get Tone Understanding.generate_response() result: \\033[93m{response['tone_understanding']}\\033[0m\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \u001b[93mBuilding a startup is no small feat. It requires a blend of passion, resilience, and a deep understanding of the market. But, how do you navigate this complex journey? Here are some insights from my experience in the AI and deeptech sectors.\n",
      "\n",
      "Firstly, it's crucial to identify a problem worth solving. Startups thrive on innovation, and the most successful ones are those that address a real, tangible problem. This is particularly true in the AI and deeptech sectors, where the potential for disruption is immense.\n",
      "\n",
      "Secondly, assemble a team that shares your vision. Building a startup is a collective effort, and having a team that is as passionate about the problem as you are can make all the difference. Remember, a startup is only as strong as its weakest link.\n",
      "\n",
      "Thirdly, be prepared to pivot. The startup journey is rarely a straight line. It's a series of twists and turns, and being able to adapt to changing circumstances is key. This is especially true in the fast-paced world of AI and deeptech, where new developments can quickly render old solutions obsolete.\n",
      "\n",
      "Lastly, never lose sight of your customers. They are the lifeblood of your startup. Listen to their feedback, understand their needs, and strive to provide them with the best possible solution.\n",
      "\n",
      "Building a startup is a challenging yet rewarding journey. It's a path filled with obstacles, but with the right mindset and approach, it can lead to incredible success. I encourage all entrepreneurs and startups to apply these insights to their businesses. \n",
      "\n",
      "For more in-depth insights and advice on building startups, particularly in the AI and deeptech sectors, feel free to check out my latest blog post [insert URL here]. \n",
      "\n",
      "#Startups #AI #Deeptech\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 464, in format\n",
      "    return self._format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 460, in _format\n",
      "    return self._fmt % values\n",
      "           ~~~~~~~~~~^~~~~~~~\n",
      "KeyError: 'collection_name'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 1160, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 999, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 706, in format\n",
      "    s = self.formatMessage(record)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 675, in formatMessage\n",
      "    return self._style.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py\", line 466, in format\n",
      "    raise ValueError('Formatting field not found in record: %s' % e)\n",
      "ValueError: Formatting field not found in record: 'collection_name'\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/zn/hrg8wdfx0ps9d2m4xyzdzypm0000gn/T/ipykernel_3077/1924308021.py\", line 7, in <module>\n",
      "    response = model.invoke(prompt)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 707, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1278, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 955, in request\n",
      "    return self._request(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 991, in _request\n",
      "    response = self._client.send(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"/Users/parthmahajan/full-stack/Flowbee/MainRepo/RAG-Tests/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1038, in _send_single_request\n",
      "    logger.info(\n",
      "Message: 'HTTP Request: %s %s \"%s %d %s\"'\n",
      "Arguments: ('POST', URL('https://api.openai.com/v1/chat/completions'), 'HTTP/1.1', 200, 'OK')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = f\"\"\"\n",
    "You are a helpful assistant that can draft a LinkedIn post.\n",
    "USING ONLY THE FOLLOWING tone, patterns and voice of the author {author_id} extracted from similar posts to the current topic, draft me a LinkedIn post discussing how to build startups.\n",
    "\n",
    "The tone, patterns and voice of the author is: {response['tone_understanding']}\n",
    "\"\"\"\n",
    "response = model.invoke(prompt)\n",
    "logger.info(f\"Response: \\033[93m{response.content}\\033[0m\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
